{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shakespear.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {c: i for i, c in enumerate(chars)}\n",
    "itos = {i: c for c, i in stoi.items()}\n",
    "encode = lambda cs: [stoi[c] for c in cs]\n",
    "decode = lambda ixs: ''.join([itos[i] for i in ixs])\n",
    "\n",
    "decode(encode(text[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003854, 111540)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = torch.tensor(encode(text), dtype=torch.long)\n",
    "trainsize = int(len(encoded_text)*0.9)\n",
    "trainset = encoded_text[:trainsize]\n",
    "valset = encoded_text[trainsize:]\n",
    "trainset.shape[0], valset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5, 57, 58,  6,  0, 32, 46, 47],\n",
       "         [42, 10,  0, 26, 53,  1, 44, 53],\n",
       "         [41, 46, 39, 52, 45, 43, 42,  0],\n",
       "         [ 1, 46, 47, 57,  1, 40, 43, 42],\n",
       "         [46, 53, 59,  1, 57, 47, 52, 43],\n",
       "         [43, 10,  0, 32, 46, 56, 47, 41],\n",
       "         [33, 31, 10,  0, 32, 46, 47, 57],\n",
       "         [50, 50,  1, 63, 53, 59,  1, 40],\n",
       "         [43,  1, 30, 53, 51, 43, 53,  1],\n",
       "         [58, 43, 56, 47, 58, 63,  6,  0],\n",
       "         [43,  1, 61, 39, 57,  1, 52, 53],\n",
       "         [58, 47, 52, 45, 57,  6,  1, 39],\n",
       "         [56, 57,  0, 16, 53,  1, 43, 60],\n",
       "         [63, 53, 59,  1, 42, 53, 61, 52],\n",
       "         [ 6,  1, 61, 46, 53, 57, 43,  1],\n",
       "         [ 5, 57,  1, 42, 39, 59, 45, 46]]),\n",
       " tensor([[57, 58,  6,  0, 32, 46, 47, 52],\n",
       "         [10,  0, 26, 53,  1, 44, 53, 53],\n",
       "         [46, 39, 52, 45, 43, 42,  0, 41],\n",
       "         [46, 47, 57,  1, 40, 43, 42,  6],\n",
       "         [53, 59,  1, 57, 47, 52, 43, 61],\n",
       "         [10,  0, 32, 46, 56, 47, 41, 43],\n",
       "         [31, 10,  0, 32, 46, 47, 57,  1],\n",
       "         [50,  1, 63, 53, 59,  1, 40, 43],\n",
       "         [ 1, 30, 53, 51, 43, 53,  1, 42],\n",
       "         [43, 56, 47, 58, 63,  6,  0, 17],\n",
       "         [ 1, 61, 39, 57,  1, 52, 53, 58],\n",
       "         [47, 52, 45, 57,  6,  1, 39, 52],\n",
       "         [57,  0, 16, 53,  1, 43, 60, 43],\n",
       "         [53, 59,  1, 42, 53, 61, 52, 10],\n",
       "         [ 1, 61, 46, 53, 57, 43,  1, 44],\n",
       "         [57,  1, 42, 39, 59, 45, 46, 58]]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 8\n",
    "batch_size = 16\n",
    "emb_dim = 32\n",
    "\n",
    "def get_batch(split):\n",
    "    data = trainset if split == 'train' else valset\n",
    "    label_idx = torch.randint(context_length, len(data), (batch_size,))\n",
    "    x = torch.stack([trainset[i-context_length:i] for i in label_idx])\n",
    "    y = torch.stack([trainset[i+1-context_length:i+1] for i in label_idx])\n",
    "    return x, y\n",
    "\n",
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, head_size, masked=True):\n",
    "        super().__init__()\n",
    "        self.masked = masked\n",
    "        self.q = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.k = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.v = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        if self.masked:\n",
    "            self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        Q, K, V = self.q(x), self.k(x), self.v(x)\n",
    "        wei = Q @ K.transpose(-1, -2)\n",
    "        if self.masked:\n",
    "            wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = wei / C**-0.5\n",
    "        return F.softmax(wei, dim=-1) @ V\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, head_size, masked=True):\n",
    "        super().__init__()\n",
    "        self.heads = [AttentionHead(head_size, masked) for i in range(n_heads)]\n",
    "        self.proj = nn.Linear(emb_dim, emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Sequential(\n",
    "        nn.Linear(emb_dim, 4*emb_dim), nn.ReLU(),\n",
    "        nn.Linear(4*emb_dim, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, n_head, head_size):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(n_head, head_size)\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.ff = FeedForward()\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.mha(self.ln1(x))\n",
    "        out = x + self.ff(self.ln2(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_heads = 4\n",
    "head_size = 8\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, n_blocks=2): \n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.position_embedding = nn.Embedding(context_length, emb_dim)\n",
    "        self.blocks = nn.Sequential(*[TransformerBlock(n_heads, head_size) for _ in range(n_blocks)])\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        token_embs = self.token_embedding(idx) # B, T -> B, T, C\n",
    "        pos_embs = self.position_embedding(torch.arange(T))\n",
    "        out = token_embs + pos_embs\n",
    "        out = self.blocks(out)\n",
    "        logits = self.lm_head(out)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, num_tokens=10_000):\n",
    "        for _ in range(num_tokens):\n",
    "            context = idx[:, -context_length:]\n",
    "            logits, _ = self(context)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, next_token), dim=1)\n",
    "        return idx\n",
    "\n",
    "model = GPT()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/100000: Loss is 4.5855\n",
      "10000/100000: Loss is 2.1049\n",
      "20000/100000: Loss is 2.0213\n",
      "30000/100000: Loss is 1.7250\n",
      "40000/100000: Loss is 1.9150\n",
      "50000/100000: Loss is 1.8335\n",
      "60000/100000: Loss is 1.9393\n",
      "70000/100000: Loss is 2.0933\n",
      "80000/100000: Loss is 1.9646\n",
      "90000/100000: Loss is 1.8829\n"
     ]
    }
   ],
   "source": [
    "train_steps = 100_000\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(eval_iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "for step in range(train_steps):\n",
    "    # forward pass\n",
    "    x, y = get_batch('train')\n",
    "    logits, loss = model(x, y)\n",
    "\n",
    "    # backward pass\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 10_000 == 0:\n",
    "        losses = estimate_loss(200) \n",
    "        train_loss = losses['train']\n",
    "        val_loss = losses['val']\n",
    "        print(f\"{step}/{train_steps} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "And thor do pray:\n",
      "My please was XFluscomppise veang'd to scond and man wish peaces a me,\n",
      "Rame, and; will with to you\n",
      "thou whered baitus o' to bede! st's pretand you, so his me.\n",
      "\n",
      "HENRY VI\n",
      "serted most this trouf, let myself to peare give of thabme.\n",
      "Bessadst in.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Nu, cked of no prarce firds'ged she\n",
      "tand abous to to the sunter of mad wish, crove.\n",
      "What as coves,\n",
      "Sucre to\n",
      "stack of teach it.\n",
      "If the sow yest he chair\n",
      "'s have to wast race?\n",
      "\n",
      "No, thoughheps.\n",
      "Who dread? while powerd was theys.\n",
      "\n",
      "DUKE\n",
      "Nor have that upserastey'st to shame. Thiy past, gothinage:\n",
      "Hear\n",
      "Of sham dyer, afrobu laitliel; see to k forth in for this eachus.\n",
      "Of honous? fitterd \n",
      "PRINCAK, I may be sthall isforgion merroblemon! lack.\n",
      "She house\n",
      "Hance,-ad my mave you force to horfurience,\n",
      "Glood day their well I spoken; tell not, have feer thee wastip,\n",
      "is to this nisten.\n",
      "\n",
      "POLGRK:\n",
      "I:\n",
      "Go, any desa,\n",
      "Thou the flow my man to levil'd dee to sufe not to do fir. the done,\n",
      "Spast is\n",
      "spuie,\n",
      "And roughts Kay!\n",
      "Now mory swite.\n",
      "Wimpt;\n",
      "Not prove.\n",
      "\n",
      "JULIET:\n",
      "ISTHe hase thy death befendlesends ards; takess a kame of our in\n",
      "cart, by see, why me, notess,\n",
      "Panfoun not sendies time of was trusty!\n",
      "\n",
      "HORCHARD TIII:\n",
      "My hat to brear to thee, taking my 'law conounief'd.\n",
      "\n",
      "JUM:\n",
      "'Twens.\n",
      "\n",
      "HEN OF AUMNESS:\n",
      "What by wraugh on foot to the use.\n",
      "\n",
      "WARWICK:\n",
      "\n",
      "GRE:\n",
      "Weixtreserved in shasts other.\n",
      "\n",
      "DY ICHESS OF AURD:\n",
      "Are staintly pleacy, succh krusts: and think, are diesident far if mall\n",
      "If thou ditnes.\n",
      "Wist old age est well it:\n",
      "\n",
      "Godest glow,\n",
      "And man well.\n",
      "\n",
      "CORCUS:\n",
      "We to bend thank'st ext\n",
      "monther\n",
      "Wild paadienger with in Grutuard wind. To to sight:\n",
      "Warls' was?\n",
      "\n",
      "Now heam begived abick, I fears.\n",
      "\n",
      "GRELONCE:\n",
      "'Ting! brother pood me theboplent rest\n",
      "I am kny the we arth will the warm unmary\n",
      "ursuann! nor sup't not soft ose of heave I yputlude, thousad he is naid it of wit inhow's to wrong thou liecome.\n",
      "\n",
      "GRUMIUS:\n",
      "My it't lack the back ormself?\n",
      "\n",
      "BRUTUS:\n",
      "Thou eart\n",
      "To gatst atten\n",
      "his ngrow,\n",
      "Which exeled by rether, isbels abinds a speech this courtand mattaGe;\n",
      "Thy ou thee as worlive up the fiul spitizen.\n",
      "\n",
      "PAULING AUslfeed wildle accep amfty be monstspief those, ungstrand this crece; whance whursessies Lae be that horating of tity that eembles they forth'\n",
      "Shirr peak you? us argaid my conse to good beglangers.\n",
      "Lray come iso\n",
      "will vencaiscounds, villistivel thusess: and, goOLo? My bait:\n",
      "My Be ward? the nobooten in sain; and his awlides tions you as him untaged and uncised be reasurcistaided.\n",
      "Well see!\n",
      "What crow'd crue'd heary be't, thou pose?\n",
      "\n",
      "ANGET:\n",
      "Such\n",
      "Will of the pen! and anigh, lead?\n",
      "\n",
      "WARCK:\n",
      "RONIA:\n",
      "God shon hurgh ame, I, and thou honad Greer to Edward stays\n",
      "adrewed in my dest me: the with oy mone thy would foolet s'tis trufairld'd sham gone; rone of boest me, the crinfuirst mesting's flulwn thouse on penere to the thou he't.\n",
      "Hosch tears and thy was him up have a\n",
      "make to'te notest me may athou wond, my dumpence his to Clan, haproble, noust grow.\n",
      "Treap?\n",
      "And hour crute meds, Edwatter\n",
      "Have post bain and fave mire.\n",
      "\n",
      "LLIE:\n",
      "I caise to ofte the abusful killa,\n",
      "No, the golient presence to thee ciming destand.\n",
      "\n",
      "CLARENCE:\n",
      "Neves,\n",
      "Af,\n",
      "And conficerest.\n",
      "\n",
      "URDIOL:\n",
      "Merceech\n",
      "be doth, lacken in themsed may kind.\n",
      "\n",
      "CORIOLON:\n",
      "'Ttell whose it lik mosts.\n",
      "Which' be me hear shalfed 'tis of lorain,--\n",
      "She morther thee words? world.\n",
      "\n",
      "TES:\n",
      "I have ush! I ursuntroat's you you Upeed to remn from earimand, if be'st stat,\n",
      "Gickle, Godd Chearewliss himse prether's? O prophave, I:\n",
      "But soulist\n",
      "When son hear\n",
      "Durgerious if henem the our up thou give, 'I not reath itse peease\n",
      "To in I'll thears? I'll\n",
      "First Rare night remet things. man be think himpstice as for sunce very fact reGet hard alie' trawy three.\n",
      "\n",
      "BUCKINGHAAM:\n",
      "\n",
      "Welcounts?\n",
      "And cay thou fear,\n",
      "Though-cons ajuce\n",
      "Ware fielind me, I'll nuse:\n",
      "Whice long lar,\n",
      "But havided the making.\n",
      "\n",
      "DORCHIOLINGHAM:\n",
      "O, the dee---\n",
      "\n",
      "LRUMIUS:\n",
      "Clown:\n",
      "Rep-care our leavent with all confentis I mawlant banding expair,\n",
      "Than thrieve nothiite to the wost me an.\n",
      "\n",
      "CLARENPA:\n",
      "My lord,'.\n",
      "\n",
      "YORK:\n",
      "Myeou that I pale, he rigod dived of you do hame:\n",
      "Swick is hanging stick'd at fathersure lose to his quked.\n",
      "\n",
      "ELLIZI:\n",
      "And stor\n",
      "Den of I am wecome? lettle the but than you to my sould in you proyse: desend hell'd the cham wome of if off:\n",
      "They dectinest, by it a plople, and my simmost I peree thyou\n",
      "I a!\n",
      "\n",
      "Shark-wear:\n",
      "Nore?\n",
      "\n",
      "CLIRCIUS:\n",
      "O best\n",
      "Magacion!\n",
      "\n",
      "MERCUTIO:\n",
      "Befer fie Gread, there than My leakind ostriong save beh me, will pliefing sucame are the reatheroutesty aye nigh set\n",
      "Thirly\n",
      "\n",
      "Peastise the king wortans\n",
      "Unest thank moef an:\n",
      "The quious,\n",
      "And last the genst's me the candly, first, flielts adver, that tastry ment's may dess prink, whose trame bhe reavence onats, it supops othe wouldingace then;\n",
      "Perst,\n",
      "Shou\n",
      "re may:\n",
      "Un tentend was irent not.\n",
      "Stres, it, tagear no, stesed of I flancles your pairscoply I of thee.\n",
      "\n",
      "AUTOLYCUS:\n",
      "When home:\n",
      "Eset is mil twhost to ach as Edward ko structage not one from improbilish to than ent taugmer? but sto boweld; for blorp, is loths you much his cond, to live the's priving ife of and is love quvere chised your day wounD:\n",
      "Sir:\n",
      "Cled and her fliening Keep all down:\n",
      "Grivence the wifed a deeds a the dead\n",
      "To lift or what conjunden?\n",
      "The pone new it't to you may,\n",
      "To-live a pidk would obr other,\n",
      "And to bless? king, all should therse ourpy that we be me,\n",
      "Do\n",
      "TyfORLAAND:\n",
      "Then by it me,\n",
      "What\n",
      "'lial's done for neve stay thank return have you charost balt.\n",
      "\n",
      "CAMERLEY VINCENTIO:\n",
      "For hat of long\n",
      "Should do light, were would age. Ladingmsern,\n",
      "God toou pood, as her,\n",
      "Edwarde-Duke:\n",
      "Which to stot sobilef ung a read?\n",
      "\n",
      "LEWIFF:\n",
      "Prive cerponw's be for eetles fant, whidiscous arwns?\n",
      "Ushe powerly not they will del daughted how I merrowell,\n",
      "Heavents;\n",
      "Pearlon:\n",
      "As faingge.\n",
      "\n",
      "WARWICK: their on the comess aday truo, of Suin:\n",
      "And that so the vere from leption of this and'st was must the whose, extothin at 'lished love not the whangbacking cobe way his pepetcili'gaze have you destit; or ween honou sort not Mows sumpds my ling the gristy,\n",
      "Sukgnous are daid, man not of Dery it the pitle merthy earys, her.\n",
      "If mock no the kneests 'tis a welcof.\n",
      "\n",
      "GRENCE YORK KING RICHARD VINCENTIO:\n",
      "Crome one:\n",
      "If may my drew! let my long;\n",
      "You carrow Lodguter\n",
      "a\n",
      "With not, as Richamful\n",
      "For dungest I cance cheponcoing Edward:\n",
      "The put the with shoud:\n",
      "Yes hold\n",
      "Edward my and any me.\n",
      "\n",
      "GLOUCESTER:\n",
      "Q:\n",
      "What fair Your might, for musy,\n",
      "To wreath with of cond he, dear\n",
      "Frovil thee thou esty bunde lands,\n",
      "hen for there life, don. I thow so the wild near will whip that her hand fear!\n",
      "\n",
      "Saw More speak no rasts me.\n",
      "\n",
      "\n",
      "ENRY VI am grie, no\n",
      "strif me:\n",
      "I am adven how man.\n",
      "\n",
      "DUKE VINCAND:\n",
      "With you now\n",
      "You tham of Your fegates.\n",
      "\n",
      "NORTHUMBERLEY:\n",
      "\n",
      "Which patimes bUrble with days, your ursed,\n",
      "To duke up hat o' prop the sached aboudn\n",
      "Wormsents a charge not\n",
      "I boot, thy live!\n",
      "Where a more 'talk.\n",
      "\n",
      "KING HENRY VI:\n",
      "And to mong your my beforatne.\n",
      "With let a thee hon willare glent to compess we things,\n",
      "Rolienged the\n",
      "say that me did\n",
      "tlew in!\n",
      "\n",
      "Secon Seep, Marcy:\n",
      "Would.\n",
      "As Peend.\n",
      "\n",
      "KING Now, tae, nord Geven mae a firence your man.\n",
      "\n",
      "ELUS:\n",
      "As a\n",
      "blest's, the faith.\n",
      "\n",
      "Sicks o' cronate no;\n",
      "Hat the proity her whastictizns;\n",
      "The ould our Julie sleast to to stay ear than.\n",
      "\n",
      "Than they lit deeds: reven.\n",
      "\n",
      "MARGALELE:\n",
      "Why gart!\n",
      "\n",
      "SARCINGHAM:\n",
      "But nouce not Rich Freath gangen thy was were it: you us, cammend con;\n",
      "Wardly.\n",
      "\n",
      "QUEEN:\n",
      "To thus.\n",
      "\n",
      "LLARESTES:\n",
      "And made from thy was her everusch! tirn of\n",
      "We you, friend, an firge, thiner:\n",
      "A taugh form profore En biny a nor consuteak of or mighby lawn lear I being.\n",
      "\n",
      "MENENIUS:\n",
      "there age:\n",
      "No!\n",
      "Not you.\n",
      "Slay, Duke rey:\n",
      "Why rough it.\n",
      "\n",
      "GLOUMBERCIOLIA:\n",
      "Ahw can you, that in to not brith; ad! Bundluift, for sconnoce;\n",
      "Addeeds, tissman you acquece theif of\n",
      "Gpode oldded, I' law'd the foults-, I am,\n",
      "Nor thang theop feave to be his man,\n",
      "You can not in hance usa their in gay that gake has pride:\n",
      "Fursom withe heard, or and of a anights there many dish hence the that disut\n",
      "hat one, Edward bead'seer's Che\n",
      "toll awardom,\n",
      "From huse stal at old me race not propeops:\n",
      "Gatinoth yet many frewnt may, whenself;\n",
      "Dead cry not onatuar shown.\n",
      "If this my have che abrit; his.\n",
      "The lifess.\n",
      "WARLINCENTIO:\n",
      "To'll\n",
      "To hit-bed the wife was teed of Groush of Vomes:\n",
      "Any prother,\n",
      "And the tant trould and sped, ime I'll thus?\n",
      "'The piess.\n",
      "What are to shey,\n",
      "our they bear thee.\n",
      "Bus?\n",
      "\n",
      "CASTILINGS:\n",
      "Theme. You trow\n",
      "BaTher slime,\n",
      "How chast ling wrist the in'g night.\n",
      "\n",
      "GLOUMMTERRENCE:\n",
      "We to power comb I meath thank; eve day\n",
      "will'd Bomurenellithes affate exery you hise or man lave wa For An my of that forbses,\n",
      "And the Jule, sick?\n",
      "No, lift!\n",
      "Plet? Signs and behen they dissmegjung is the not again the so roce; which dest's long friuss you;\n",
      "I in death the frard and to twixtstior tolit,\n",
      "For glead,\n",
      "Then straine be stirects\n",
      "uch!\n",
      "A beserven:\n",
      "Which.\n",
      "\n",
      "GLOUMERLE:\n",
      "And mie\n",
      "A very of rives, I thou man should I w nongles turn nused you I madon coldly the bahk draw, and and; and exed the cause our had be.\n",
      "Un to think'st it, some mented mave drose.\n",
      "there say eighers, boulas neat to might\n",
      "A dies ae\n",
      "kee;\n",
      "Aty, night Romeo, Friomst?\n",
      "Our the from oun likes being it of\n",
      "Which he come of our tughted,\n",
      "And to ben Peart than I thou secome,\n",
      "I wrait?\n",
      "\n",
      "GREPINTIO:\n",
      "Are a grue, and of\n",
      "Deamst in, nor make shoul than you grungent Bonfohaple-so: dry's and who be't on\n",
      "Ah lifebit trath?'\n",
      "\n",
      "HASTIO:\n",
      "Your our jew\n",
      "Thou fare read, my like himsee to kng\n",
      "eye turnmitest unrow be himst, him the strifed firlk\n",
      "GnoINIUS:\n",
      "Hes arrow.\n",
      "Now nown ive in.\n",
      "\n",
      "PERLIZABETH:\n",
      "Look vereect stael be to youndsmmine you come turn and the dests,\n",
      "And whils;\n",
      "You and maillist's ust confoe; when likes in hone.\n",
      "\n",
      "DUCETIM:\n",
      "We his the cant usudjugh.\n",
      "\n",
      "BENCENVINCE:\n",
      "I have how leardom forporoup,\n",
      "Begen in my loave Angly stue was, Caplact, there mand so merpair thich pround how, or thank our loung oncuiside I the blook\n",
      "Were a Rick'd?\n",
      "\n",
      "TRICHARD III:\n",
      "Smost their sad, the seivence? peatop negive they can tummenttlest beel?\n",
      "\n",
      "BENVEN AUMERLE:\n",
      "Blast you, And sededly afrien to morth cant\n",
      "I weit the wrivence a king?\n",
      "\n",
      "GLOUMNENENIUS:\n",
      "My gon.\n",
      "\n",
      "ISTwen?\n",
      "The knig!\n",
      "\n",
      "AUTOLY:\n",
      "\n",
      "You contraw, in kind swith for my gry seedp, and day\n",
      "Grange\n",
      "Teary.\n",
      "\n",
      "CORIOLIAnd; res\n"
     ]
    }
   ],
   "source": [
    "generated_idx = model.generate(torch.zeros((1,1), dtype=torch.long))[0].tolist()\n",
    "print(decode(generated_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
