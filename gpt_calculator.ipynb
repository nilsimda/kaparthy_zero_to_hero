{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "emb_dim = 32\n",
    "max_digits = 6 # maximum number of digits in the two numbers we are adding/mutliplying/dividing\n",
    "context_length = 2*max_digits + 2*max_digits + 2 # number1 * number2 = number3 (which can have 2*max_digits)\n",
    "batch_size = 32\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, masked=True):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.masked = masked\n",
    "        self.q = nn.Linear(emb_dim, emb_dim, bias=False) #compute for all heads in parrallel, n_heads * head_size = emb_dim\n",
    "        self.k = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.v = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.proj = nn.Linear(emb_dim, emb_dim)\n",
    "        if self.masked:\n",
    "            self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        Q, K, V = self.q(x), self.k(x), self.v(x)\n",
    "        Q = Q.view(B, T, self.n_heads, C//self.n_heads).transpose(1,2) #self attention needs to be done individually for each head\n",
    "        K = K.view(B, T, self.n_heads, C//self.n_heads).transpose(1,2) #transpose needed so we do self attention in the given char context not between the different heads\n",
    "        V = V.view(B, T, self.n_heads, C//self.n_heads).transpose(1,2)\n",
    "        wei = Q @ K.transpose(-1, -2)\n",
    "        if self.masked:\n",
    "            wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = wei / C**-0.5\n",
    "        out = F.softmax(wei, dim=-1) @ V\n",
    "        out = out.transpose(1,2).contiguous().view(B, T, C)\n",
    "        return self.proj(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Sequential(\n",
    "        nn.Linear(emb_dim, 4*emb_dim), nn.ReLU(),\n",
    "        nn.Linear(4*emb_dim, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, n_head):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(n_head)\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.ff = FeedForward()\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.mha(self.ln1(x))\n",
    "        out = x + self.ff(self.ln2(x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, n_heads=4, n_blocks=2): \n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.position_embedding = nn.Embedding(context_length, emb_dim)\n",
    "        self.blocks = nn.Sequential(*[TransformerBlock(n_heads) for _ in range(n_blocks)])\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        token_embs = self.token_embedding(idx) # B, T -> B, T, C\n",
    "        pos_embs = self.position_embedding(torch.arange(T))\n",
    "        out = token_embs + pos_embs\n",
    "        out = self.blocks(out)\n",
    "        logits = self.lm_head(out)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def calculate(self, idx, max_tokens=100):\n",
    "        for _ in range(max_tokens): # just to make sure we dont run into infinite loop if model fails to end its output\n",
    "            context = idx[:, -context_length:]\n",
    "            logits, _ = self(context)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.argmax(probs, keepdim=True) # use argmax instead of multinomial, there is only one correct answer\n",
    "            idx = torch.cat((idx, next_token), dim=1)\n",
    "            if next_token == 15:\n",
    "                break\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2,  5,  3,  9,  0,  9, 10,  9,  1,  6,  3,  3,  6, 14,  5,  4,  2,  0,\n",
       "          7,  1,  1,  0,  0,  0,  0,  0]),\n",
       " tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100,    5,    4,    2,    0,    7,    1,    1,    0,    0,    0,    0,\n",
       "            0,   15]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {'+': 10, '*':11, '/': 12, '=': 14, '<END>':15}\n",
    "itos= {i: op for op, i in stoi.items()}\n",
    "\n",
    "def encode(num1, num2, op, res=None):\n",
    "    # encode symbols\n",
    "    op_enc = torch.tensor(stoi[op], dtype=torch.long).view(1)\n",
    "    equals_enc = torch.tensor(stoi['='], dtype=torch.long).view(1)\n",
    "\n",
    "    def _encode_num(num, num_digits, reverse=False):\n",
    "        if reverse:\n",
    "            out = torch.tensor([int(digit) for digit in reversed(str(num).zfill(num_digits))], dtype=torch.long)\n",
    "        else:\n",
    "            out = torch.tensor([int(digit) for digit in str(num).zfill(num_digits)], dtype=torch.long)\n",
    "        return out\n",
    "\n",
    "    # encode input numbers (left pad with zeros until max_digits)\n",
    "    num1_enc = _encode_num(num1, max_digits)\n",
    "    num2_enc = _encode_num(num2, max_digits)\n",
    "\n",
    "    if res == None:\n",
    "        out = torch.cat([num1_enc, op_enc, num2_enc, equals_enc])\n",
    "    else:\n",
    "        res_enc = _encode_num(res, 2*max_digits, True)\n",
    "        out = torch.cat([num1_enc, op_enc, num2_enc, equals_enc, res_enc])\n",
    "\n",
    "    return out\n",
    "\n",
    "def decode(x):\n",
    "    out = []\n",
    "    for idx in x:\n",
    "        if idx < 10: out.append(str(idx.item())) # if its a digit just add it as a str\n",
    "        elif idx == stoi['<END>']: break # END token means we are done\n",
    "        else: out.append(itos[idx.item()]) # otherwise encode op\n",
    "\n",
    "    return \"\".join(out)\n",
    "\n",
    "# we sample two random numbers as input and their sum as the label\n",
    "def sample_mathproblems(num_problems): \n",
    "    ops = torch.randint(10, 12, (num_problems, ), dtype=torch.long)\n",
    "    all_nums = torch.randint(0, 10**(max_digits)-1, (num_problems, 2), dtype=torch.long)\n",
    "    \n",
    "    x = torch.zeros((num_problems, context_length), dtype=torch.long)\n",
    "\n",
    "    for i, (nums, op) in enumerate(zip(all_nums, ops)):\n",
    "        num1, num2 = nums[0].item(), nums[1].item()\n",
    "        op_c = itos[op.item()]\n",
    "        match op_c:\n",
    "            case '+':\n",
    "                res = num1 + num2\n",
    "            case '*':\n",
    "                res = num1 * num2\n",
    "            case '/':\n",
    "                res = num1 // num2\n",
    "        x[i] = encode(num1, num2, op_c, res)\n",
    "\n",
    "    input_size = 2*max_digits+2\n",
    "    masked_loss = -100 * torch.ones((num_problems, input_size-1), dtype=torch.long)\n",
    "    end_token = stoi['<END>'] * torch.ones((num_problems, 1), dtype=torch.long)\n",
    "    y = torch.cat([masked_loss, x[:, input_size:], end_token], dim=1)\n",
    "    return x, y\n",
    "\n",
    "n_samples = 1_000_000\n",
    "x, y = sample_mathproblems(n_samples)\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([800000, 26]),\n",
       " torch.Size([800000, 26]),\n",
       " torch.Size([100000, 26]),\n",
       " torch.Size([100000, 26]),\n",
       " torch.Size([100000, 26]),\n",
       " torch.Size([100000, 26]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * n_samples)\n",
    "val_size = int(0.9 * n_samples)\n",
    "x_train, y_train = x[:train_size], y[:train_size]\n",
    "x_val, y_val = x[train_size:val_size], y[train_size:val_size]\n",
    "x_test, y_test = x[val_size:], y[val_size:]\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            if split == 'train':\n",
    "                idx = torch.randint(0, len(x_train), (batch_size, ))\n",
    "                X, Y = x_train[idx], y_train[idx]\n",
    "            elif split == 'val':\n",
    "                idx = torch.randint(0, len(x_val), (batch_size, ))\n",
    "                X, Y = x_val[idx], y_val[idx]\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "def train_gpt(model, optimizer, train_steps=100_000, eval_iters=200):\n",
    "    for step in range(train_steps):\n",
    "        # forward pass\n",
    "        idx = torch.randint(0, len(x_train), (batch_size,))\n",
    "        x, y = x_train[idx], y_train[idx]\n",
    "        _, loss = model(x, y)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 10_000 == 0:\n",
    "            losses = estimate_loss(model, eval_iters) \n",
    "            train_loss = losses['train']\n",
    "            val_loss = losses['val']\n",
    "            print(f\"{step}/{train_steps} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/100000 - Train Loss: 2.9064, Val Loss: 2.9089\n",
      "10000/100000 - Train Loss: 1.0955, Val Loss: 1.0995\n",
      "20000/100000 - Train Loss: 0.9225, Val Loss: 0.9389\n",
      "30000/100000 - Train Loss: 0.8842, Val Loss: 0.9027\n",
      "40000/100000 - Train Loss: 0.8825, Val Loss: 0.8954\n",
      "50000/100000 - Train Loss: 0.8562, Val Loss: 0.8997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m GPT(\u001b[39m16\u001b[39m)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m train_gpt(model, optimizer, train_steps\u001b[39m=\u001b[39;49m\u001b[39m100_000\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[53], line 29\u001b[0m, in \u001b[0;36mtrain_gpt\u001b[0;34m(model, optimizer, train_steps, eval_iters)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39m# backward pass\u001b[39;00m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 29\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     30\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m10_000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/general/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/general/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GPT(16)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_gpt(model, optimizer, train_steps=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100000+100000=0000120000000'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1 = 100000\n",
    "num2 = 100000\n",
    "prob1 = encode(num1, num2, '+').view(1, -1)\n",
    "res_enc = model.calculate(prob1)[0]\n",
    "decode(res_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
